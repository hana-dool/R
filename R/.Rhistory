library(broom)
# Load the data
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
# Load the data
data("PimaIndiansDiabetes2", package = "mlbench")
data
PimaIndiansDiabetes2
PimaIndiansDiabetes2
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
# Load the data
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
```{r}
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
require(tidyverse)
require(broom)
require(mlbench)
require(broom)
require(mlbench)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
require(tidyverse)
require(broom)
require(mlbench)
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
require(tidyverse)
require(broom)
require(mlbench)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
plot(model, which = 4, id.n = 3)
model.data <- augment(model) %>%
mutate(index = 1:n())
model.data %>% top_n(3, .cooksd)
ggplot(model.data, aes(index, .std.resid)) +
geom_point(aes(color = diabetes), alpha = .5) +
theme_bw()
model.data %>%
filter(abs(.std.resid) > 3)
car::vif(model)
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Chunk 1: setup
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
# Chunk 2
require(tidyverse)
require(broom)
require(mlbench)
# Chunk 3
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
# Chunk 4
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
# Chunk 5
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
facet_wrap(~predictors, scales = "free_y")
# Chunk 6
plot(model, which = 4, id.n = 3)
# Chunk 7
model.data <- augment(model) %>%
mutate(index = 1:n())
# Chunk 8
model.data %>% top_n(3, .cooksd)
# Chunk 9
ggplot(model.data, aes(index, .std.resid)) +
geom_point(aes(color = diabetes), alpha = .5) +
theme_bw()
# Chunk 10
model.data %>%
filter(abs(.std.resid) > 3)
# Chunk 11
car::vif(model)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
```{r}
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
facet_wrap(~predictors, scales = "free_y")
# 살펴보기
head(PimaIndiansDiabetes2)
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
head(predicted.classes)
%>%
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
mydata <- mtcars %>%
select_if(is.numeric)
mydata
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
mydata
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
PimaIndiansDiabetes2
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
# 일렬로 해체한 데이터를 그래프로 그려본다.
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
plot(model, which = 4, id.n = 3)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes= as.factor(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes= as.numeric(PimaIndiansDiabetes2$diabetes)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
str(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabete
PimaIndiansDiabetes2$diabetes
PimaIndiansDiabetes2$diabetes == 'neg'
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=0
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'pos']=0
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
as.str(PimaIndiansDiabetes2$diabetes)
as.character(PimaIndiansDiabetes2$diabetes)
# 살펴보기
head(PimaIndiansDiabetes2)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
as.character(PimaIndiansDiabetes2$diabetes)
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
PimaIndiansDiabetes2$diabetes = as.character(PimaIndiansDiabetes2$diabetes)
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'pos']=0
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes = as.numeric(PimaIndiansDiabetes2$diabetes)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
PimaIndiansDiabetes2
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes = as.numeric(PimaIndiansDiabetes2$diabetes)
PimaIndiansDiabetes2
PimaIndiansDiabetes2$diabetes = as.numeric(as.character(PimaIndiansDiabetes2$diabetes))
PimaIndiansDiabetes2
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes = as.numeric(as.character(PimaIndiansDiabetes2$diabetes))
PimaIndiansDiabetes2
PimaIndiansDiabetes2$diabetes = as.numeric(as.character(PimaIndiansDiabetes2$diabetes))
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes = as.numeric(as.character(PimaIndiansDiabetes2$diabetes))
PimaIndiansDiabetes2$diabetes = (as.character(PimaIndiansDiabetes2$diabetes)
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
str(PimaIndiansDiabetes2)
PimaIndiansDiabetes2$diabetes = as.character(PimaIndiansDiabetes2$diabetes)
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'neg']=1
PimaIndiansDiabetes2$diabetes[PimaIndiansDiabetes2$diabetes == 'pos']=0
PimaIndiansDiabetes2
str(PimaIndiansDiabetes2)
as.numeric(PimaIndiansDiabetes2$diabetes)
PimaIndiansDiabetes2$diabetes = as.numeric(PimaIndiansDiabetes2$diabetes)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
summary(model)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
summary(model)
str(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
summary(model)
# Predict the probability (p) of diabete positivity
# predict 할 때에 response 라고 하게 되면 확률값을 예측한다.
probabilities <- predict(model, type = "response")
# 0.5를 초과하면 positive 라고 예측된것이므로, 예측하는 class 를 생성하자.
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
# 예측된 class 의 앞 값들
head(predicted.classes)
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
# log probability 를 원래 선형회귀때에 적합했던 scale 로 변환
mutate(logit = log(probabilities/(1-probabilities))) %>%
# gather 을 통해서 predictor 을 모두 해채한다음, 일렬로 이어붙인다.
gather(key = "predictors", value = "predictor.value", -logit)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
# log probability 를 원래 선형회귀때에 적합했던 scale 로 변환
mutate(logit = log(probabilities/(1-probabilities))) %>%
# gather 을 통해서 predictor 을 모두 해채한다음, 일렬로 이어붙인다.
gather(key = "predictors", value = "predictor.value", -logit)
require(tidyverse)
require(broom)
require(mlbench)
require(dplyr)
# 데이터 로드하기
data("PimaIndiansDiabetes2", package = "mlbench")
# NA 값 제거하기
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# 살펴보기
head(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
summary(model)
# Predict the probability (p) of diabete positivity
# predict 할 때에 response 라고 하게 되면 확률값을 예측한다.
probabilities <- predict(model, type = "response")
# 0.5를 초과하면 positive 라고 예측된것이므로, 예측하는 class 를 생성하자.
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
# 예측된 class 의 앞 값들
head(predicted.classes)
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
# log probability 를 원래 선형회귀때에 적합했던 scale 로 변환
mutate(logit = log(probabilities/(1-probabilities))) %>%
# gather 을 통해서 predictor 을 모두 해채한다음, 일렬로 이어붙인다.
gather(key = "predictors", value = "predictor.value", -logit)
# 일렬로 해체한 데이터를 그래프로 그려본다.
ggplot(mydata, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
# Select only numeric predictors
mydata <- PimaIndiansDiabetes2 %>%
select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
# log probability 를 원래 선형회귀때에 적합했던 scale 로 변환
mutate(logit = log(probabilities/(1-probabilities))) %>%
# gather 을 통해서 predictor 을 모두 해채한다음, 일렬로 이어붙인다.
gather(key = "predictors", value = "predictor.value", -logit)
# 일렬로 해체한 데이터를 그래프로 그려본다.
ggplot(mydata, aes(predictor.value,logit))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
# 일렬로 해체한 데이터를 그래프로 그려본다.
ggplot(mydata, aes(predictor.value,logit))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_x")
plot(model, which = 4, id.n = 3)
model.data <- augment(model) %>%
mutate(index = 1:n())
model.data <- augment(model) %>%
mutate(index = 1:n())
plot(model, which = 4, id.n = 3)
plot(model, which = 4, id.n = 3)
plot(model, which = 4, id.n = 3)
```{r}
model.data <- augment(model) %>%
mutate(index = 1:n())
model.data <- augment(model) %>%
mutate(index = 1:n())
model.data %>% top_n(3, .cooksd)
ggplot(model.data, aes(index, .std.resid)) +
geom_point(aes(color = diabetes), alpha = .5) +
theme_bw()
model.data %>%
filter(abs(.std.resid) > 3)
car::vif(model)
plot(model, which = 4, id.n = 3)
model.data <- augment(model) %>%
mutate(index = 1:n())
model.data <- augment(model) %>%
mutate(index = 1:n())
model.data %>% top_n(3, .cooksd)
ggplot(model.data, aes(index, .std.resid)) +
geom_point(aes(color = diabetes), alpha = .5) +
theme_bw()
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial) # 이때 family = binomial 로 해야 logistic 이 된다.
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,family = binomial)
summary(model)
